---
title: "TransPRS"
author: "Lyu Ruiqi"
date: "2021/9/24"
output: html_document
---

## Introduction

TransPRS is a package that is used to fit the transfer-lasso on big genomics data. We assume the genodata are stored in .vcf format and the phenodata are stored with FID IID and quantified phenotypes in  text format (for example, .txt format).

```{r, eval=FALSE}
Trans.global<-function(X.tarLis, y.tarLis, X.srcLis, y.srcLis,
                       phenotype = phenotype, split.col = NULL,
                       covariates = covariates, get_path = get_path,
                       configs = configs, nlambda = 30, lambda.min.ratio = 0.01, p = p,
                       family, id_type = "double", agg=T, ValProp = 1/10, alpha = 1, nsplit = 4, shortcut = T)
```

The most essential parameters in the core function snpnet include:

- **X.tarLis**: X.tarLis = paste0(XXX, ".vcf")

- **y.tarLis**: y.tarLis = paste0(XXX, ".phe") .phe file can be generated from .txt with FID IID and phenotype columns by function `pheGen`

- **X.srcLis**: X.srcLis = paste0(XXX, ".vcf")

- **y.srcLis**: X.srcLis = paste0(XXX, ".phe") .phe file can be generated from .txt with FID IID and phenotype columns by function `pheGen`

- **phenotype**: the name of the phenotype. Must be the same as the corresponding column name in the phenotype file. 

- **split.col**: the column name in the phenotype file that specifies the membership of individuals to the training or the validation set. The individuals marked as "train" and "val" will be treated as the training and validation set, respectively. When specified, the model performance is evaluated on both the training and the validation sets.

- **covariates**: a character vector containing the names of the covariates included in the lasso fitting, whose coefficients will not be penalized. The names must exist in the column names of the phenotype file.

- **get_path**: dir for saving the intermediate files and result files.

- **configs**: a list of other config parameters.

- **nlambda**: the number of lambda values - default is 50.

- **lambda.min.ratio**: smallest value for lambda, as a fraction of lambda.max, the (data derived) entry value, i.e. the smallest value for which all coefficients are zero. The default depends on the sample size nobs relative to the number of actual variables nvars (after QC filtering). The default is 0.01. A very small value of lambda.min.ratio will lead to a saturated fit in the nobs < nvars case.

- **p**: number of SNPs in genofile.

- **family**: the type of the phenotype: "gaussian", "binomial".

- **id_type**: "underline" or "double", depend on the sample names in VCF files. The default is "double". if the sample name is 'FID_IID', choose id_type="underline" if the sample name is 'IID' alone , choose id_type="double".

- **agg**: whether to remove aggregate results after the end of the functions. default is T.

- **ValProp**: the proportion of validating set for aggregation when spliting the primary sample files for later aggregation. default is 1/10.

- **alpha**: the elastic-net mixing parameter, where the penalty is defined as alpha * ||beta||_1 + (1-alpha)/2 * ||beta||_2^2. alpha = 1 corresponds to the lasso penalty, while alpha = 0 corresponds to the ridge penalty.

- **nsplit**: split number of X and beta that we can product part by part to reduce memory use. default is 4.

- **shortcut**: whether to avoid using tuned lambda to caltulate the parameters on all samples again. If the sample size is large enough, let shortcut = T can save computational costs.

`TransPRS` is built on `snpnet`, which depends on two other programs plink2, zstd and zstdcat. If they are not already on the system serach path, it is important to specify their locations in the configs object and pass it to `snpnet`.

```{r}
library(TransPRS)
```

```{r}
plink2.path = "~/TransLasso+snpnet/plink2"
zstdcat.path = "~/.conda/envs/sy_Env/bin/zstdcat"
zstd.path = "~/.conda/envs/sy_Env/bin/zstd"
get_path <- paste0(system.file(package = 'TransPRS'), "/extdata")
configs <- list(
  # results.dir = "PATH/TO/SAVE/DIR",  # needed when saving intermediate results
  # save = TRUE,  # save intermediate results per iteration (default FALSE)
  # nCores = 16,  # number of cores available (default 1)
  # niter = 100,  # max number of iterations (default 50)
  # prevIter = 15,  # if we want to start from some iteration saved in results.dir
  # use.glmnetPlus = TRUE,  # recommended for faster computation
  # early.stopping = FALSE,  # whether to stop based on validation performance (default TRUE)
  plink2.path = plink2.path,   # path to plink2 program
  zstdcat.path = zstdcat.path,  # path to zstdcat program
  zstd.path = zstd.path
)
# check if the provided paths are valid
for (name in names(configs)) {
  tryCatch(system(paste(configs[[name]], "-h"), ignore.stdout = T),
           condition = function(e) cat("Please add", configs[[name]], "to PATH, or modify the path in the configs list.") ) }

```


## A Simple Example

We demonstrate a simple TransGlobal example first. We provide with datasets including 3 different populations from 3 sites. 6 datasets, AFR\_sel\_site1, EAS\_sel\_site1, EAS\_sel\_site2, EUR\_sel\_site1, EUR\_sel\_site2, EUR\_sel\_site3, are used for training, and AFR\_test\_site1 is used for out-sample testing. Those with .vcf suffix are genofiles and .txt is for phenofiles (including columns for phenotypes and covariates). The format of the examples are shown as:
```{}
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	HG1s00442	HG1s00458	HG1s00463
1	833223	1:833223	C	T	.	.	PR	GT	0/1	0/0	0/1
1	839103	1:839103	A	G	.	.	PR	GT	0/1	1/1	1/1
1	845274	1:845274	G	T	.	.	PR	GT	0/0	1/1	0/1
1	901607	1:901607	G	C	.	.	PR	GT	0/0	0/0	0/1
1	928416	1:928416	G	A	.	.	PR	GT	0/0	0/0	0/1
```

```{}
HG1s00442 HG1s00442 0 1 33
HG1s00458 HG1s00458 1 0 51
HG1s00463 HG1s00463 0 1 52
HG1s00472 HG1s00472 0 0 49
HG1s00475 HG1s00475 1 1 48
```

First, we set the input filename list as:
```{r}
tarLis = paste0(get_path, "/AFR_sel_site", 1)
srcLis = list()
srcLis[[1]] = paste0(get_path, "/EAS_sel_site", 1:2)
srcLis[[2]] = paste0(get_path, "/EUR_sel_site", 1:3)
phenotype <- "QPHE"
covariates <- c("Sex", "Age")
p = 1000
```

```{r}
tarLis
srcLis
```

Then we should use `pheGen` to transform text file into `snpnet` input file (with `split.col` and train/test ratio can be specified by `split_vec`). Also, we should remove the annotations of vcf files using function `remove_anno`, or the program can have some errors.
```{r}
## generate phenofiles that snpnet needs
for(nm in c(tarLis, unlist(srcLis))){
  pheGen(ori_phefile = paste0(nm, ".txt"), phenotype, covariates = covariates, offset = NULL, split.col = "split", out_phefile = paste0(nm, ".phe"), split_vec = c(0.9, 0.1))
  # remove annotation at first
  remove_anno(paste0(nm, ".vcf"))
  # if no pfile
  # options(warn = -1)
  # pgenGen(out_pgen_name = paste0(nm), vcf.file = paste0(nm, ".vcf"), "double")
}
```

Then specify the input parameters:
```{r}
X.tarLis = paste0(tarLis, ".vcf")
y.tarLis = paste0(tarLis, ".phe")
X.srcLis = list()
y.srcLis = list()
for(i in 1:length(srcLis)){
  X.srcLis[[i]] = paste0(srcLis[[i]], ".vcf")
  y.srcLis[[i]] = paste0(srcLis[[i]], ".phe")
}
```

```{r}
X.tarLis
y.tarLis
X.srcLis
y.srcLis
```

Run the function `Trans.Global`
```{r, results='hide'}
TG <- Trans.global(X.tarLis, y.tarLis, X.srcLis, y.srcLis,
                    phenotype = phenotype, split.col = "split",
                    covariates = covariates, get_path = get_path,
                    configs = configs, nlambda = 10, lambda.min.ratio = 0.01, p = p, 
                    family = 'gaussian', id_type = "double", 
                    agg=T, ValProp = 1/8, alpha = 1, nsplit = 5, shortcut = T)

```

```{r, results='hide'}
# example for binomial cases
TG_bn <- Trans.global(X.tarLis, y.tarLis, X.srcLis, y.srcLis,
                    phenotype = phenotype, split.col = "split",
                    covariates = covariates, get_path = get_path,
                    configs = configs, nlambda = 10, lambda.min.ratio = 0.01, p = p, 
                    family = 'binomial', id_type = "double", 
                    agg=T, ValProp = 1/8, alpha = 0.5, nsplit = 5, shortcut = F)

```

The coefficients can be extracted by `$beta.hat`.

```{r}
cat(TG$beta.hat[1:10])

cat(TG$eta.hat)

cat(TG_bn$beta.hat[1:10])

cat(TG_bn$eta.hat)
```

```{r}
metric = c()
testLis = paste0(get_path, "/AFR_test_site", 1)
for(nm in c(tarLis, testLis)){
  pheGen(ori_phefile = paste0(nm, ".txt"), phenotype, covariates = covariates, offset = NULL, split.col = "split", out_phefile = paste0(nm, ".phe"), split_vec = c(0.9, 0.1))
  # remove annotation at first
  remove_anno(paste0(nm, ".vcf"))
  # if no pfile
  pgenGen(out_pgen_name = paste0(nm), vcf.file = paste0(nm, ".vcf"), "double")
  # computeMetric <- function(pred, response, metric.type = 'auc')
  pred = Xbeta_product(nm, TG$beta.hat[-(1:(1+length(covariates)))], p, nsplit = 4) + TG$beta.hat[1]
  response = read.csv(paste0(nm, ".phe"), header = T)
  response = response[, phenotype] - as.matrix(response[, covariates]) %*% TG$beta.hat[2:(1+length(covariates))] 
  metric = c(metric, (cor(pred, response))^2)
  # metric = c(metric, snpnet:::computeMetric(pred, response, metric.type = 'auc'))
  system(paste0("rm ", nm, ".pgen"))
  system(paste0("rm ", nm, ".psam"))
  system(paste0("rm ", nm, ".pvar*"))
}

for(nm in c(tarLis, unlist(srcLis), testLis)){
  system(paste0("rm ", nm, ".phe"))
}

cat('\nResult:', metric, '\n')
```